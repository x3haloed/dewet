[bridge]
listen_addr = "127.0.0.1:7777"
max_clients = 4

[vision]
capture_interval_ms = 8000
diff_threshold = 0.12
max_history = 12

[observation]
chat_depth = 30
screen_history = 8
# Memory management (Aria's "forgetting without amnesia")
forget_threshold = 0.3     # Messages below this relevance are "cold"
decay_rate = 0.92          # Relevance multiplier per minute (0.92 = ~50% after 8 min)
max_vlm_messages = 15      # Only send top N relevant messages to VLM

[storage]
url = "file:./.local/dewet.db"
auth_token_env = "TURSO_AUTH_TOKEN"

[director]
min_decision_interval_ms = 2000
cooldown_after_speak_ms = 120000

[llm]
# VLA (Vision-Language Analysis) - fast, cheap vision model for change detection
# Runs most frequently (~every 8 seconds), needs vision capability
[llm.vla]
provider = { type = "lmstudio", endpoint = "http://127.0.0.1:1234" }
model = "qwen/qwen3-vl-4b"

# Arbiter - reasoning model for deciding who should speak
# Needs vision to see screen context, benefits from strong reasoning
[llm.arbiter]
provider = { type = "openrouter", api_key_env = "OPENROUTER_API_KEY", site_url = "https://dewet.dev", site_name = "Dewet" }
model = "qwen/qwen2.5-vl-32b-instruct"

# Response - creative writing model for generating character dialogue
# Benefits from strong conversational/creative writing ability
[llm.response]
provider = { type = "openrouter", api_key_env = "OPENROUTER_API_KEY", site_url = "https://dewet.dev", site_name = "Dewet" }
model = "x-ai/grok-4-fast"

[tts]
provider = "null"

