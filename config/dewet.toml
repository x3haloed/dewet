[bridge]
listen_addr = "127.0.0.1:7777"
max_clients = 4

[vision]
capture_interval_ms = 8000
diff_threshold = 0.12
max_history = 12

[observation]
chat_depth = 30
screen_history = 8
# Memory management (Aria's "forgetting without amnesia")
forget_threshold = 0.3     # Messages below this relevance are "cold"
decay_rate = 0.92          # Relevance multiplier per minute (0.92 = ~50% after 8 min)
max_vlm_messages = 15      # Only send top N relevant messages to VLM

[storage]
url = "file:./.local/dewet.db"
auth_token_env = "TURSO_AUTH_TOKEN"

[director]
min_decision_interval_ms = 2000
cooldown_after_speak_ms = 30000

[llm]
provider = { type = "openrouter", api_key_env = "OPENROUTER_API_KEY", site_url = "https://dewet.dev", site_name = "Dewet" }
decision_model = "google/gemini-2.5-flash"  # Fast vision model for VLM analysis
response_model = "x-ai/grok-4.1-fast:free"

[tts]
provider = "null"

